{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dictionary(dict): \n",
    "  \n",
    "    # __init__ function \n",
    "    def __init__(self): \n",
    "        self = dict() \n",
    "          \n",
    "    # Function to add key:value \n",
    "    def add(self, key, value): \n",
    "        self[key] = value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df = pd.read_csv('../csvFiles/goodreadersRowfile.csv')\n",
    "dfwin = pd.read_csv('../AwardDates.csv')\n",
    "data = dict()\n",
    "with open('../RowData/dates.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "for d in data: \n",
    "    date = d['date']\n",
    "    result = re.search('Published(.*)', date)\n",
    "    partial = result.group(1)\n",
    "    if('by' in partial) :\n",
    "        partial = re.search('(.*)by', partial)\n",
    "        d['date'] = partial.group(1).lstrip().rstrip()\n",
    "    else:\n",
    "        d['date'] = partial.lstrip().rstrip()\n",
    "\n",
    "with open('../RowData/cleanPublishDay.json', 'w') as new:\n",
    "    json.dump(data, new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " calculating dates and matching isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dict()\n",
    "with open('../RowData/cleanPublishDay.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "mapUrlDate = my_dictionary()\n",
    "mapUrlIsbn = my_dictionary()\n",
    "isbnList = list()\n",
    "for d in data:\n",
    "\n",
    "    ds = str(d['date']).split()\n",
    "    if len(ds)>1:\n",
    "        ds[1]=ds[1].replace('th','').replace('st','').replace('rd','').replace('nd','')\n",
    "        d['date'] = ''.join(str(e)+' ' for e in ds)\n",
    "    if len(ds)>3:\n",
    "         d['date'] = ''.join([ds[0],' ',ds[1],' ',ds[2],' '])\n",
    "    try:\n",
    "        d['date']=datetime.strptime(d['date'], '%B %d %Y ')\n",
    "    except ValueError :\n",
    "        try:\n",
    "           d['date']= datetime.strptime(d['date'], '%B %Y ')\n",
    "        except ValueError :\n",
    "           d['date']= datetime.strptime(d['date'], '%Y')\n",
    "    if(df[df['url']==d['url']].empty):\n",
    "        continue\n",
    "    year=df[df['url']==d['url']]['year'].iloc[0]\n",
    "    win=datetime.strptime(dfwin[dfwin['year'] ==year]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "    if((win -  d['date']).days<1):\n",
    "        d['date']=(win -  d['date']).days + 365\n",
    "    else:\n",
    "        d['date']=(win -  d['date']).days \n",
    "    mapUrlDate.add(d['url'], d['date'])\n",
    "    mapUrlIsbn.add(d['url'],d['isbn'])\n",
    "    isbnList.append(d['isbn'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging data and adding 'times_appred_NYTime','avgrank_NYTime','bestRank','listnames' to are coulems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUD=pd.DataFrame(mapUrlDate.items(), columns=['url', 'daysToContest'])\n",
    "dfUI = pd.DataFrame(mapUrlIsbn.items(), columns=['url', 'isbn'])\n",
    "df.merge(dfUD,on='url', how='left').merge(dfUI,on='url', how='left').to_csv(\"../csvFiles/goodreadsfinaldata.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding newyork times data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csvFiles/goodreadsfinaldata.csv')\n",
    "df = df.reindex(df.columns.tolist() + ['times_appred_NYTime','avgrank_NYTime','bestRank','listnames'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorhandler_isbn(isbn):\n",
    "    df.loc[df['isbn']==isbn,['times_appred_NYTime']] = 0\n",
    "    df.loc[df['isbn']==isbn,['avgrank_NYTime']] =float('inf')\n",
    "    df.loc[df['isbn']==isbn,['bestRank']] = float('inf')\n",
    "    df.loc[df['isbn']==isbn,['listnames']] = 0\n",
    "def nans(df): return df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading newYork Data and adding to feilds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3350\n"
     ]
    }
   ],
   "source": [
    "newYork_dir = \"../newYork Data/\"\n",
    "data = dict()\n",
    "data1 = dict()\n",
    "for filename in os.listdir(newYork_dir):\n",
    "    if filename.endswith(\".json\") and filename.startswith(\"res\") and not(filename.endswith(\"10.json\")): \n",
    "        cmplt_path = os.path.join(newYork_dir, filename)\n",
    "        with open(cmplt_path) as json_file :\n",
    "            new_data = json.load(json_file)\n",
    "            data.update(new_data)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(len(data))\n",
    "for i in isbnList:\n",
    "    try:\n",
    "        if d[i]['num_results']==0:\n",
    "                errorhandler_isbn(i)\n",
    "                continue\n",
    "        for j in data[i]['results']:\n",
    "            bestrank=float('inf')\n",
    "            num=0\n",
    "            count = 0 \n",
    "            listname = set()\n",
    "            if len(j['ranks_history'])==0:\n",
    "                errorhandler_isbn(i)\n",
    "                continue\n",
    "            year = df[df['isbn']==i]['year']\n",
    "            win=datetime.strptime(dfwin[dfwin['year'] ==year]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "            for z in j['ranks_history']:\n",
    "                if(datetime.strptime(z['published_date'], '%Y-%m-%d')<win):\n",
    "                    num+= z['rank']\n",
    "                    listname.add(z['list_name'])\n",
    "                    if bestrank>z['rank']:\n",
    "                        bestrank =z['rank']\n",
    "                    count  = count + 1\n",
    "            num=num/count\n",
    "            df.loc[df['isbn']==i,['times_appred_NYTime']] = count\n",
    "            df.loc[df['isbn']==i,['avgrank_NYTime']] =num\n",
    "            df.loc[df['isbn']==i,['bestRank']] = bestrank\n",
    "            df.loc[df['isbn']==i,['listnames']] = len(listname)\n",
    "    except KeyError :\n",
    "        errorhandler_isbn(i)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../csvFiles/withNYdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cheak nall values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csvFiles/withNYdata.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data from json 11 with different struct and saving to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../newYork Data/res10.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "for i in data:\n",
    "    if data[i]['num_results']==0:\n",
    "        errorhandler_isbn(i)\n",
    "        continue\n",
    "    for j in data[i]['results']:\n",
    "        bestrank=float('inf')\n",
    "        num=0\n",
    "        listname = set()\n",
    "        if len(j['ranks_history'])==0:\n",
    "                errorhandler_isbn(i)\n",
    "                continue\n",
    "        year = df[df['url']==i]['year']\n",
    "        for k in year:\n",
    "            win=datetime.strptime(dfwin[dfwin['year'] ==k]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "            for z in j['ranks_history']:\n",
    "                if(datetime.strptime(z['published_date'], '%Y-%m-%d')<win):\n",
    "                    num+= z['rank']\n",
    "                    listname.add(z['list_name'])\n",
    "                    if bestrank>z['rank']:\n",
    "                        bestrank =z['rank']\n",
    "                    count  = count + 1\n",
    "            num=num/count\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['times_appred_NYTime']] = count\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['avgrank_NYTime']] =num\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['bestRank']] = bestrank\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['listnames']] = str(len(listname))\n",
    "df.to_csv(\"../csvFiles/withNYdata.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving nulls in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nans(df): return df[df.isnull().any(axis=1)]\n",
    "nans(df).to_csv(\"nulls.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
