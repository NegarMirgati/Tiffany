{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dictionary(dict): \n",
    "  \n",
    "    # __init__ function \n",
    "    def __init__(self): \n",
    "        self = dict() \n",
    "          \n",
    "    # Function to add key:value \n",
    "    def add(self, key, value): \n",
    "        self[key] = value \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'goodreads_output3.csv' does not exist: b'goodreads_output3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a39b6ce987e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'goodreads_output3.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdfwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AwardDates.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mona/newDates.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'goodreads_output3.csv' does not exist: b'goodreads_output3.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('goodreads_output3.csv')\n",
    "dfwin = pd.read_csv('AwardDates.csv')\n",
    "data = dict()\n",
    "with open('mona/newDates.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "for d in data: \n",
    "    date = d['date']\n",
    "    result = re.search('Published(.*)', date)\n",
    "    partial = result.group(1)\n",
    "    if('by' in partial) :\n",
    "        partial = re.search('(.*)by', partial)\n",
    "        d['date'] = partial.group(1).lstrip().rstrip()\n",
    "    else:\n",
    "        d['date'] = partial.lstrip().rstrip()\n",
    "\n",
    "with open('mona/new.json', 'w') as new:\n",
    "    json.dump(data, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mona/new.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5a8112998721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calculating dates and matching isbn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mona/new.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mona/new.json'"
     ]
    }
   ],
   "source": [
    "# calculating dates and matching isbn\n",
    "data = dict()\n",
    "with open('mona/new.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "hi = my_dictionary()\n",
    "h2 = my_dictionary()\n",
    "h3 = list()\n",
    "for d in data:\n",
    "\n",
    "    ds = str(d['date']).split()\n",
    "    if len(ds)>1:\n",
    "        ds[1]=ds[1].replace('th','').replace('st','').replace('rd','').replace('nd','')\n",
    "        d['date'] = ''.join(str(e)+' ' for e in ds)\n",
    "    if len(ds)>3:\n",
    "         d['date'] = ''.join([ds[0],' ',ds[1],' ',ds[2],' '])\n",
    "    try:\n",
    "        d['date']=datetime.strptime(d['date'], '%B %d %Y ')\n",
    "    except ValueError :\n",
    "        try:\n",
    "           d['date']= datetime.strptime(d['date'], '%B %Y ')\n",
    "        except ValueError :\n",
    "           d['date']= datetime.strptime(d['date'], '%Y')\n",
    "    if(df[df['url']==d['url']].empty):\n",
    "        continue\n",
    "    year=df[df['url']==d['url']]['year'].iloc[0]\n",
    "    win=datetime.strptime(dfwin[dfwin['year'] ==year]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "    if((win -  d['date']).days<1):\n",
    "        d['date']=(win -  d['date']).days + 365\n",
    "    else:\n",
    "        d['date']=(win -  d['date']).days \n",
    "#     if (d['name'] == 'Calling Dr. Laura'):\n",
    "#         print(d['date'])\n",
    "#         print(win)\n",
    "    hi.add(d['url'], d['date'])\n",
    "    h2.add(d['url'],d['isbn'])\n",
    "    h3.append(d['isbn'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging data and adding 'times_appred_NYTime','avgrank_NYTime','bestRank','listnames' to are coulems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b25f1e25128b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'daystocom'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdfnew1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'isbn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfnew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfnew1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"withdays.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'withdays.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'times_appred_NYTime'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'avgrank_NYTime'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bestRank'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'listnames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hi' is not defined"
     ]
    }
   ],
   "source": [
    "dfnew=pd.DataFrame(hi.items(), columns=['url', 'daystocom'])\n",
    "dfnew1 = pd.DataFrame(h2.items(), columns=['url', 'isbn'])\n",
    "df.merge(dfnew,on='url', how='left').merge(dfnew1,on='url', how='left').to_csv(\"withdays.csv\")\n",
    "df = pd.read_csv('withdays.csv')\n",
    "df = df.reindex(df.columns.tolist() + ['times_appred_NYTime','avgrank_NYTime','bestRank','listnames'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading newYork Data and adding to feilds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newYork Data/res8.json\n",
      "newYork Data/res4.json\n",
      "newYork Data/res5.json\n",
      "newYork Data/res10.json\n",
      "newYork Data/res9.json\n",
      "newYork Data/res2.json\n",
      "newYork Data/res3.json\n",
      "newYork Data/res1.json\n",
      "newYork Data/res6.json\n",
      "newYork Data/res7.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'h3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-eaedb8da7b13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'English'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h3' is not defined"
     ]
    }
   ],
   "source": [
    "data = dict()\n",
    "newYork_dir = \"newYork Data/\"\n",
    "data = dict()\n",
    "data1 = dict()\n",
    "for filename in os.listdir(newYork_dir):\n",
    "    if (filename.endswith(\".json\") and filename.startswith(\"res\")): \n",
    "        cmplt_path = os.path.join(newYork_dir, filename)\n",
    "        print(cmplt_path)\n",
    "        with open(cmplt_path) as json_file :\n",
    "            new_data = json.load(json_file)\n",
    "            data.update(new_data)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for i in h3:\n",
    "    try:\n",
    "        if i =='English': continue\n",
    "        if len(data[i]['results'])==0:\n",
    "                df.loc[df['isbn']==i,['times_appred_NYTime']] = 0\n",
    "                df.loc[df['isbn']==i,['avgrank_NYTime']] =float('inf')\n",
    "                df.loc[df['isbn']==i,['bestRank']] = float('inf')\n",
    "                df.loc[df['isbn']==i,['listnames']] = str(0)\n",
    "                continue\n",
    "        for j in data[i]['results']:\n",
    "            bestrank=float('inf')\n",
    "            num=0\n",
    "            count = 0 \n",
    "            listname = set()\n",
    "            if len(j['ranks_history'])==0:\n",
    "                df.loc[df['isbn']==i,['times_appred_NYTime']] =0\n",
    "                df.loc[df['isbn']==i,['avgrank_NYTime']] =float('inf')\n",
    "                df.loc[df['isbn']==i,['bestRank']] = float('inf')\n",
    "                df.loc[df['isbn']==i,['listnames']] = str(0)\n",
    "                continue\n",
    "            year = df[df['isbn']==i]['year']\n",
    "#             print(year)\n",
    "            for k in year:\n",
    "                win=datetime.strptime(dfwin[dfwin['year'] ==k]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "                for z in j['ranks_history']:\n",
    "                    if(datetime.strptime(z['published_date'], '%Y-%m-%d')<win):\n",
    "                        num+= z['rank']\n",
    "                        listname.add(z['list_name'])\n",
    "                        if bestrank>z['rank']:\n",
    "                            bestrank =z['rank']\n",
    "                        count  = count + 1\n",
    "                    if count>0:\n",
    "                        num=num/count\n",
    "                        df.loc[df['isbn']==i,['times_appred_NYTime']] = count\n",
    "                        df.loc[df['isbn']==i,['avgrank_NYTime']] =num\n",
    "                        df.loc[df['isbn']==i,['bestRank']] = bestrank\n",
    "                        df.loc[df['isbn']==i,['listnames']] = str(len(listname))\n",
    "                    else:\n",
    "                        df.loc[df['isbn']==i,['times_appred_NYTime']] = 0\n",
    "                        df.loc[df['isbn']==i,['avgrank_NYTime']] =float('inf')\n",
    "                        df.loc[df['isbn']==i,['bestRank']] = float('inf')\n",
    "                        df.loc[df['isbn']==i,['listnames']] = str(0)\n",
    "                        \n",
    "    except KeyError :\n",
    "        print(i)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e9e97ad18133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"withdays.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"withdays.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cheak nall values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>writer</th>\n",
       "      <th>category</th>\n",
       "      <th>winner</th>\n",
       "      <th>num 1 stars</th>\n",
       "      <th>num 2 stars</th>\n",
       "      <th>...</th>\n",
       "      <th>average_rating_w</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>url</th>\n",
       "      <th>daystocom</th>\n",
       "      <th>isbn</th>\n",
       "      <th>times_appred_NYTime</th>\n",
       "      <th>avgrank_NYTime</th>\n",
       "      <th>bestRank</th>\n",
       "      <th>listnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "      <td>2013</td>\n",
       "      <td>Orphan Train</td>\n",
       "      <td>['Christina Baker Kline']</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>...</td>\n",
       "      <td>4.09</td>\n",
       "      <td>417138.0</td>\n",
       "      <td>35762.0</td>\n",
       "      <td>https://www.goodreads.com/book/show/15818107-o...</td>\n",
       "      <td>246.0</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alpha &amp; Omega</td>\n",
       "      <td>['Joe Hill', 'Gabriel Rodríguez']</td>\n",
       "      <td>Graphic Novels &amp; Comics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.03</td>\n",
       "      <td>658776.0</td>\n",
       "      <td>59771.0</td>\n",
       "      <td>https://www.goodreads.com/book/show/16164271-a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>666</td>\n",
       "      <td>666</td>\n",
       "      <td>666</td>\n",
       "      <td>2014</td>\n",
       "      <td>What If?: Serious Scientific Answers to Absurd...</td>\n",
       "      <td>['Randall Munroe']</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.16</td>\n",
       "      <td>132666.0</td>\n",
       "      <td>9829.0</td>\n",
       "      <td>https://www.goodreads.com/book/show/21413662-w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>2014</td>\n",
       "      <td>Make It Ahead: A Barefoot Contessa Cookbook</td>\n",
       "      <td>['Ina Garten']</td>\n",
       "      <td>Food &amp; Cookbooks</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016722</td>\n",
       "      <td>0.060201</td>\n",
       "      <td>...</td>\n",
       "      <td>4.16</td>\n",
       "      <td>166255.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>https://www.goodreads.com/book/show/20697389-m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>2015</td>\n",
       "      <td>The Wicked + The Divine, Vol. 2: Fandemonium</td>\n",
       "      <td>['Kieron Gillen', 'Jamie McKelvie', 'Matt Wils...</td>\n",
       "      <td>Graphic Novels &amp; Comics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/24666002-t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>979</td>\n",
       "      <td>979</td>\n",
       "      <td>979</td>\n",
       "      <td>979</td>\n",
       "      <td>2015</td>\n",
       "      <td>Angles of Attack</td>\n",
       "      <td>['Marko Kloos']</td>\n",
       "      <td>Science Fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.11</td>\n",
       "      <td>77265.0</td>\n",
       "      <td>4197.0</td>\n",
       "      <td>https://www.goodreads.com/book/show/23470865-a...</td>\n",
       "      <td>224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1206</td>\n",
       "      <td>1206</td>\n",
       "      <td>1206</td>\n",
       "      <td>1206</td>\n",
       "      <td>2012</td>\n",
       "      <td>Clockworks</td>\n",
       "      <td>['Joe Hill', 'Gabriel Rodríguez']</td>\n",
       "      <td>Graphic Novels &amp; Comics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>...</td>\n",
       "      <td>4.03</td>\n",
       "      <td>659090.0</td>\n",
       "      <td>59783.0</td>\n",
       "      <td>https://www.goodreads.com/book/show/13490570-c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1609</td>\n",
       "      <td>1609</td>\n",
       "      <td>1609</td>\n",
       "      <td>1609</td>\n",
       "      <td>2017</td>\n",
       "      <td>The Wicked + The Divine, Vol. 5: Imperial Phas...</td>\n",
       "      <td>['Kieron Gillen', 'Jamie McKelvie', 'Matt Wils...</td>\n",
       "      <td>Graphic Novels &amp; Comics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/33585540-t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>2018</td>\n",
       "      <td>The Wicked + The Divine, Vol. 6: Imperial Phas...</td>\n",
       "      <td>['Kieron Gillen', 'Jamie McKelvie', 'Matt Wils...</td>\n",
       "      <td>Graphic Novels &amp; Comics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.050336</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/35651693-t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2362</td>\n",
       "      <td>2362</td>\n",
       "      <td>2362</td>\n",
       "      <td>2362</td>\n",
       "      <td>2018</td>\n",
       "      <td>A Court of Wings and Ruin</td>\n",
       "      <td>['Sarah J. Maas']</td>\n",
       "      <td>Best of the Best</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.070922</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/23766634-a...</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1408857901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2429</td>\n",
       "      <td>2429</td>\n",
       "      <td>2429</td>\n",
       "      <td>2429</td>\n",
       "      <td>2011</td>\n",
       "      <td>Keys to the Kingdom</td>\n",
       "      <td>['Joe Hill', 'Gabriel Rodríguez']</td>\n",
       "      <td>Graphic Novels &amp; Comics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>...</td>\n",
       "      <td>4.03</td>\n",
       "      <td>658776.0</td>\n",
       "      <td>59771.0</td>\n",
       "      <td>https://www.goodreads.com/book/show/9674335-ke...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2016</td>\n",
       "      <td>Black Panther #1</td>\n",
       "      <td>['Ta-Nehisi Coates', 'Brian Stelfreeze']</td>\n",
       "      <td>Graphic Novels &amp; Comics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.033670</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/29812803-b...</td>\n",
       "      <td>244.0</td>\n",
       "      <td>B01BCPZBWI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2876</td>\n",
       "      <td>2876</td>\n",
       "      <td>2876</td>\n",
       "      <td>2876</td>\n",
       "      <td>2016</td>\n",
       "      <td>The Wicked + The Divine, Vol. 3: Commercial Su...</td>\n",
       "      <td>['Kieron Gillen', 'Jamie McKelvie', 'Tula Lota...</td>\n",
       "      <td>Graphic Novels &amp; Comics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/25853351-t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2996</td>\n",
       "      <td>2996</td>\n",
       "      <td>2996</td>\n",
       "      <td>2996</td>\n",
       "      <td>2016</td>\n",
       "      <td>Stuff Ive Been Feeling Lately</td>\n",
       "      <td>['Alicia Cook']</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>...</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3401.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>https://www.goodreads.com/book/show/29059581-s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  year  \\\n",
       "341          341           341             341  2013   \n",
       "407          407           407             407  2014   \n",
       "666          666           666             666  2014   \n",
       "778          778           778             778  2014   \n",
       "808          808           808             808  2015   \n",
       "979          979           979             979  2015   \n",
       "1206        1206          1206            1206  2012   \n",
       "1609        1609          1609            1609  2017   \n",
       "1996        1996          1996            1996  2018   \n",
       "2362        2362          2362            2362  2018   \n",
       "2429        2429          2429            2429  2011   \n",
       "2875        2875          2875            2875  2016   \n",
       "2876        2876          2876            2876  2016   \n",
       "2996        2996          2996            2996  2016   \n",
       "\n",
       "                                                   name  \\\n",
       "341                                        Orphan Train   \n",
       "407                                       Alpha & Omega   \n",
       "666   What If?: Serious Scientific Answers to Absurd...   \n",
       "778         Make It Ahead: A Barefoot Contessa Cookbook   \n",
       "808        The Wicked + The Divine, Vol. 2: Fandemonium   \n",
       "979                                    Angles of Attack   \n",
       "1206                                         Clockworks   \n",
       "1609  The Wicked + The Divine, Vol. 5: Imperial Phas...   \n",
       "1996  The Wicked + The Divine, Vol. 6: Imperial Phas...   \n",
       "2362                          A Court of Wings and Ruin   \n",
       "2429                                Keys to the Kingdom   \n",
       "2875                                   Black Panther #1   \n",
       "2876  The Wicked + The Divine, Vol. 3: Commercial Su...   \n",
       "2996                      Stuff Ive Been Feeling Lately   \n",
       "\n",
       "                                                 writer  \\\n",
       "341                           ['Christina Baker Kline']   \n",
       "407                   ['Joe Hill', 'Gabriel Rodríguez']   \n",
       "666                                  ['Randall Munroe']   \n",
       "778                                      ['Ina Garten']   \n",
       "808   ['Kieron Gillen', 'Jamie McKelvie', 'Matt Wils...   \n",
       "979                                     ['Marko Kloos']   \n",
       "1206                  ['Joe Hill', 'Gabriel Rodríguez']   \n",
       "1609  ['Kieron Gillen', 'Jamie McKelvie', 'Matt Wils...   \n",
       "1996  ['Kieron Gillen', 'Jamie McKelvie', 'Matt Wils...   \n",
       "2362                                  ['Sarah J. Maas']   \n",
       "2429                  ['Joe Hill', 'Gabriel Rodríguez']   \n",
       "2875           ['Ta-Nehisi Coates', 'Brian Stelfreeze']   \n",
       "2876  ['Kieron Gillen', 'Jamie McKelvie', 'Tula Lota...   \n",
       "2996                                    ['Alicia Cook']   \n",
       "\n",
       "                     category  winner  num 1 stars  num 2 stars  ...  \\\n",
       "341                   Fiction       0     0.006689     0.023411  ...   \n",
       "407   Graphic Novels & Comics       0     0.000000     0.003333  ...   \n",
       "666                Nonfiction       0     0.003356     0.000000  ...   \n",
       "778          Food & Cookbooks       1     0.016722     0.060201  ...   \n",
       "808   Graphic Novels & Comics       0     0.000000     0.023490  ...   \n",
       "979           Science Fiction       0     0.000000     0.030000  ...   \n",
       "1206  Graphic Novels & Comics       0     0.000000     0.012158  ...   \n",
       "1609  Graphic Novels & Comics       0     0.000000     0.020067  ...   \n",
       "1996  Graphic Novels & Comics       0     0.013423     0.050336  ...   \n",
       "2362         Best of the Best       0     0.024823     0.070922  ...   \n",
       "2429  Graphic Novels & Comics       0     0.000000     0.003356  ...   \n",
       "2875  Graphic Novels & Comics       0     0.006734     0.033670  ...   \n",
       "2876  Graphic Novels & Comics       0     0.016667     0.103333  ...   \n",
       "2996                   Poetry       0     0.009009     0.099099  ...   \n",
       "\n",
       "      average_rating_w  num_ratings  num_reviews  \\\n",
       "341               4.09     417138.0      35762.0   \n",
       "407               4.03     658776.0      59771.0   \n",
       "666               4.16     132666.0       9829.0   \n",
       "778               4.16     166255.0       1704.0   \n",
       "808                NaN          NaN          NaN   \n",
       "979               4.11      77265.0       4197.0   \n",
       "1206              4.03     659090.0      59783.0   \n",
       "1609               NaN          NaN          NaN   \n",
       "1996               NaN          NaN          NaN   \n",
       "2362               NaN          NaN          NaN   \n",
       "2429              4.03     658776.0      59771.0   \n",
       "2875               NaN          NaN          NaN   \n",
       "2876               NaN          NaN          NaN   \n",
       "2996              3.85       3401.0        614.0   \n",
       "\n",
       "                                                    url  daystocom  \\\n",
       "341   https://www.goodreads.com/book/show/15818107-o...      246.0   \n",
       "407   https://www.goodreads.com/book/show/16164271-a...        NaN   \n",
       "666   https://www.goodreads.com/book/show/21413662-w...        NaN   \n",
       "778   https://www.goodreads.com/book/show/20697389-m...        NaN   \n",
       "808   https://www.goodreads.com/book/show/24666002-t...        NaN   \n",
       "979   https://www.goodreads.com/book/show/23470865-a...      224.0   \n",
       "1206  https://www.goodreads.com/book/show/13490570-c...        NaN   \n",
       "1609  https://www.goodreads.com/book/show/33585540-t...        NaN   \n",
       "1996  https://www.goodreads.com/book/show/35651693-t...        NaN   \n",
       "2362  https://www.goodreads.com/book/show/23766634-a...      217.0   \n",
       "2429  https://www.goodreads.com/book/show/9674335-ke...        NaN   \n",
       "2875  https://www.goodreads.com/book/show/29812803-b...      244.0   \n",
       "2876  https://www.goodreads.com/book/show/25853351-t...        NaN   \n",
       "2996  https://www.goodreads.com/book/show/29059581-s...        NaN   \n",
       "\n",
       "            isbn  times_appred_NYTime avgrank_NYTime  bestRank listnames  \n",
       "341      English                  NaN            NaN       NaN       NaN  \n",
       "407          NaN                  NaN            NaN       NaN       NaN  \n",
       "666          NaN                  NaN            NaN       NaN       NaN  \n",
       "778          NaN                  NaN            NaN       NaN       NaN  \n",
       "808          NaN                  NaN            NaN       NaN       NaN  \n",
       "979          NaN                  0.0            inf       inf       0.0  \n",
       "1206         NaN                  NaN            NaN       NaN       NaN  \n",
       "1609         NaN                  NaN            NaN       NaN       NaN  \n",
       "1996         NaN                  NaN            NaN       NaN       NaN  \n",
       "2362  1408857901                  0.0            inf       inf       0.0  \n",
       "2429         NaN                  NaN            NaN       NaN       NaN  \n",
       "2875  B01BCPZBWI                  0.0            inf       inf       0.0  \n",
       "2876         NaN                  NaN            NaN       NaN       NaN  \n",
       "2996         NaN                  NaN            NaN       NaN       NaN  \n",
       "\n",
       "[14 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('withdays.csv')\n",
    "\n",
    "def nans(df): return df[df.isnull().any(axis=1)]\n",
    "nans(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data from json 11 with different struct and saving to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfwin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f5d735e9072e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mwin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfwin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfwin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Winners Announced'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%m/%d/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ranks_history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'published_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfwin' is not defined"
     ]
    }
   ],
   "source": [
    "with open('newYork Data/remained.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "for i in data:\n",
    "    if len(data[i]['results'])==0:\n",
    "        df.loc[df['url']==i,['times_appred_NYTime']] = float('inf')\n",
    "        df.loc[df['url']==i,['avgrank_NYTime']] =float('inf')\n",
    "        df.loc[df['url']==i,['bestRank']] = float('inf')\n",
    "        df.loc[df['url']==i,['listnames']] = str(0)\n",
    "        continue\n",
    "    for j in data[i]['results']:\n",
    "        bestrank=float('inf')\n",
    "        num=0\n",
    "        listname = set()\n",
    "        if len(j['ranks_history'])==0:\n",
    "                df.loc[df['url']==i,['times_appred_NYTime']] = float('inf')\n",
    "                df.loc[df['url']==i,['avgrank_NYTime']] =float('inf')\n",
    "                df.loc[df['url']==i,['bestRank']] = float('inf')\n",
    "                df.loc[df['url']==i,['listnames']] = str(0)\n",
    "                continue\n",
    "        year = df[df['url']==i]['year']\n",
    "        for k in year:\n",
    "            win=datetime.strptime(dfwin[dfwin['year'] ==k]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "            for z in j['ranks_history']:\n",
    "                if(datetime.strptime(z['published_date'], '%Y-%m-%d')<win):\n",
    "                    num+= z['rank']\n",
    "                    listname.add(z['list_name'])\n",
    "                    if bestrank>z['rank']:\n",
    "                        bestrank =z['rank']\n",
    "                    count  = count + 1\n",
    "            num=num/count\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['times_appred_NYTime']] = count\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['avgrank_NYTime']] =num\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['bestRank']] = bestrank\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['listnames']] = str(len(listname))\n",
    "df.to_csv(\"withdays.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving nulls in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nans(df): return df[df.isnull().any(axis=1)]\n",
    "nans(df).to_csv(\"nulls.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnew=pd.DataFrame(hi.items(), columns=['url', 'daystocom'])\n",
    "# dfnew1 = pd.DataFrame(h2.items(), columns=['url', 'isbn'])\n",
    "# # dfnew2 = pd.DataFrame(h5.items(), columns=['isbn', 'times_appred_NYTime'])\n",
    "# # dfnew3 = pd.DataFrame(h4.items(), columns=['isbn', 'avgrank_NYTime'])\n",
    "# # dfnew4 = pd.DataFrame(h6.items(), columns=['isbn', 'bestRank'])\n",
    "# # dfnew5 = pd.DataFrame(h7.items(), columns=['isbn', 'listnames'])\n",
    "# df.merge(dfnew,on='url', how='left').merge(dfnew1,on='url', how='left').to_csv(\"withdays.csv\")\n",
    "# # .merge(dfnew3,on='isbn', how='left').merge(dfnew4,on='isbn', how='left').merge(dfnew5,on='isbn', how='left').to_csv(\"withdays.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
