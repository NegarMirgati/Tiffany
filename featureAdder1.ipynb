{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dictionary(dict): \n",
    "  \n",
    "    # __init__ function \n",
    "    def __init__(self): \n",
    "        self = dict() \n",
    "          \n",
    "    # Function to add key:value \n",
    "    def add(self, key, value): \n",
    "        self[key] = value \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "df = pd.read_csv('goodreads_output3.csv')\n",
    "dfwin = pd.read_csv('AwardDates.csv')\n",
    "data = dict()\n",
    "with open('mona/newDates.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "for d in data: \n",
    "    date = d['date']\n",
    "    result = re.search('Published(.*)', date)\n",
    "    partial = result.group(1)\n",
    "    if('by' in partial) :\n",
    "        partial = re.search('(.*)by', partial)\n",
    "        d['date'] = partial.group(1).lstrip().rstrip()\n",
    "    else:\n",
    "        d['date'] = partial.lstrip().rstrip()\n",
    "\n",
    "with open('mona/new.json', 'w') as new:\n",
    "    json.dump(data, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating dates and matching isbn\n",
    "data = dict()\n",
    "with open('mona/new.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "hi = my_dictionary()\n",
    "h2 = my_dictionary()\n",
    "h3 = list()\n",
    "for d in data:\n",
    "\n",
    "    ds = str(d['date']).split()\n",
    "    if len(ds)>1:\n",
    "        ds[1]=ds[1].replace('th','').replace('st','').replace('rd','').replace('nd','')\n",
    "        d['date'] = ''.join(str(e)+' ' for e in ds)\n",
    "    if len(ds)>3:\n",
    "         d['date'] = ''.join([ds[0],' ',ds[1],' ',ds[2],' '])\n",
    "    try:\n",
    "        d['date']=datetime.strptime(d['date'], '%B %d %Y ')\n",
    "    except ValueError :\n",
    "        try:\n",
    "           d['date']= datetime.strptime(d['date'], '%B %Y ')\n",
    "        except ValueError :\n",
    "           d['date']= datetime.strptime(d['date'], '%Y')\n",
    "    if(df[df['url']==d['url']].empty):\n",
    "        continue\n",
    "    year=df[df['url']==d['url']]['year'].iloc[0]\n",
    "    win=datetime.strptime(dfwin[dfwin['year'] ==year]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "    if((win -  d['date']).days<1):\n",
    "        d['date']=(win -  d['date']).days + 365\n",
    "    else:\n",
    "        d['date']=(win -  d['date']).days \n",
    "#     if (d['name'] == 'Calling Dr. Laura'):\n",
    "#         print(d['date'])\n",
    "#         print(win)\n",
    "    hi.add(d['url'], d['date'])\n",
    "    h2.add(d['url'],d['isbn'])\n",
    "    h3.append(d['isbn'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging data and adding 'times_appred_NYTime','avgrank_NYTime','bestRank','listnames' to are coulems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew=pd.DataFrame(hi.items(), columns=['url', 'daystocom'])\n",
    "dfnew1 = pd.DataFrame(h2.items(), columns=['url', 'isbn'])\n",
    "df.merge(dfnew,on='url', how='left').merge(dfnew1,on='url', how='left').to_csv(\"withdays.csv\")\n",
    "df = pd.read_csv('withdays.csv')\n",
    "df = df.reindex(df.columns.tolist() + ['times_appred_NYTime','avgrank_NYTime','bestRank','listnames'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading newYork Data and adding to feilds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438\n",
      "870\n",
      "1295\n",
      "1405\n",
      "1810\n",
      "2245\n",
      "2690\n",
      "3146\n",
      "3350\n"
     ]
    }
   ],
   "source": [
    "data = dict()\n",
    "data1 = dict()\n",
    "with open('newYork Data/res1.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "print(len(data))\n",
    "with open('newYork Data/res2.json') as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "data.update(data1)\n",
    "print(len(data))\n",
    "with open('newYork Data/res4.json') as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "data.update(data1)\n",
    "print(len(data))\n",
    "with open('newYork Data/res5.json') as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "data.update(data1)\n",
    "print(len(data))\n",
    "with open('newYork Data/res6.json') as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "data.update(data1)\n",
    "print(len(data))\n",
    "with open('newYork Data/res7.json') as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "data.update(data1)\n",
    "print(len(data))\n",
    "with open('newYork Data/res8.json') as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "data.update(data1)\n",
    "print(len(data))\n",
    "with open('newYork Data/res9.json') as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "data.update(data1)\n",
    "print(len(data))\n",
    "with open('newYork Data/res10.json') as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "data.update(data1)\n",
    "print(len(data))\n",
    "for i in h3:\n",
    "    try:\n",
    "        if i =='English': continue\n",
    "        if len(data[i]['results'])==0:\n",
    "                df.loc[df['isbn']==i,['times_appred_NYTime']] = 0\n",
    "                df.loc[df['isbn']==i,['avgrank_NYTime']] =float('inf')\n",
    "                df.loc[df['isbn']==i,['bestRank']] = float('inf')\n",
    "                df.loc[df['isbn']==i,['listnames']] = str(0)\n",
    "                continue\n",
    "        for j in data[i]['results']:\n",
    "            bestrank=float('inf')\n",
    "            num=0\n",
    "            count = 0 \n",
    "            listname = set()\n",
    "            if len(j['ranks_history'])==0:\n",
    "                df.loc[df['isbn']==i,['times_appred_NYTime']] =0\n",
    "                df.loc[df['isbn']==i,['avgrank_NYTime']] =float('inf')\n",
    "                df.loc[df['isbn']==i,['bestRank']] = float('inf')\n",
    "                df.loc[df['isbn']==i,['listnames']] = str(0)\n",
    "                continue\n",
    "            year = df[df['isbn']==i]['year']\n",
    "#             print(year)\n",
    "            for k in year:\n",
    "                win=datetime.strptime(dfwin[dfwin['year'] ==k]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "                for z in j['ranks_history']:\n",
    "                    if(datetime.strptime(z['published_date'], '%Y-%m-%d')<win):\n",
    "                        num+= z['rank']\n",
    "                        listname.add(z['list_name'])\n",
    "                        if bestrank>z['rank']:\n",
    "                            bestrank =z['rank']\n",
    "                        count  = count + 1\n",
    "                    if count>0:\n",
    "                        num=num/count\n",
    "                        df.loc[df['isbn']==i,['times_appred_NYTime']] = count\n",
    "                        df.loc[df['isbn']==i,['avgrank_NYTime']] =num\n",
    "                        df.loc[df['isbn']==i,['bestRank']] = bestrank\n",
    "                        df.loc[df['isbn']==i,['listnames']] = str(len(listname))\n",
    "                    else:\n",
    "                        df.loc[df['isbn']==i,['times_appred_NYTime']] = 0\n",
    "                        df.loc[df['isbn']==i,['avgrank_NYTime']] =float('inf')\n",
    "                        df.loc[df['isbn']==i,['bestRank']] = float('inf')\n",
    "                        df.loc[df['isbn']==i,['listnames']] = str(0)\n",
    "                        \n",
    "    except KeyError :\n",
    "        print(i)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"withdays.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cheak nall values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('withdays.csv')\n",
    "\n",
    "def nans(df): return df[df.isnull().any(axis=1)]\n",
    "nans(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data from json 11 with different struct and saving to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newYork Data/res11.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "for i in data:\n",
    "    if len(data[i]['results'])==0:\n",
    "        df.loc[df['url']==i,['times_appred_NYTime']] = float('inf')\n",
    "        df.loc[df['url']==i,['avgrank_NYTime']] =float('inf')\n",
    "        df.loc[df['url']==i,['bestRank']] = float('inf')\n",
    "        df.loc[df['url']==i,['listnames']] = str(0)\n",
    "        continue\n",
    "    for j in data[i]['results']:\n",
    "        bestrank=float('inf')\n",
    "        num=0\n",
    "        listname = set()\n",
    "        if len(j['ranks_history'])==0:\n",
    "                df.loc[df['url']==i,['times_appred_NYTime']] = float('inf')\n",
    "                df.loc[df['url']==i,['avgrank_NYTime']] =float('inf')\n",
    "                df.loc[df['url']==i,['bestRank']] = float('inf')\n",
    "                df.loc[df['url']==i,['listnames']] = str(0)\n",
    "                continue\n",
    "        year = df[df['url']==i]['year']\n",
    "        for k in year:\n",
    "            win=datetime.strptime(dfwin[dfwin['year'] ==k]['Winners Announced'].iloc[0],'%m/%d/%Y')\n",
    "            for z in j['ranks_history']:\n",
    "                if(datetime.strptime(z['published_date'], '%Y-%m-%d')<win):\n",
    "                    num+= z['rank']\n",
    "                    listname.add(z['list_name'])\n",
    "                    if bestrank>z['rank']:\n",
    "                        bestrank =z['rank']\n",
    "                    count  = count + 1\n",
    "            num=num/count\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['times_appred_NYTime']] = count\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['avgrank_NYTime']] =num\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['bestRank']] = bestrank\n",
    "            df.loc[(df['url']==i)&(df['year']==k),['listnames']] = str(len(listname))\n",
    "df.to_csv(\"withdays.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving nulls in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nans(df): return df[df.isnull().any(axis=1)]\n",
    "nans(df).to_csv(\"nulls.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnew=pd.DataFrame(hi.items(), columns=['url', 'daystocom'])\n",
    "# dfnew1 = pd.DataFrame(h2.items(), columns=['url', 'isbn'])\n",
    "# # dfnew2 = pd.DataFrame(h5.items(), columns=['isbn', 'times_appred_NYTime'])\n",
    "# # dfnew3 = pd.DataFrame(h4.items(), columns=['isbn', 'avgrank_NYTime'])\n",
    "# # dfnew4 = pd.DataFrame(h6.items(), columns=['isbn', 'bestRank'])\n",
    "# # dfnew5 = pd.DataFrame(h7.items(), columns=['isbn', 'listnames'])\n",
    "# df.merge(dfnew,on='url', how='left').merge(dfnew1,on='url', how='left').to_csv(\"withdays.csv\")\n",
    "# # .merge(dfnew3,on='isbn', how='left').merge(dfnew4,on='isbn', how='left').merge(dfnew5,on='isbn', how='left').to_csv(\"withdays.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
