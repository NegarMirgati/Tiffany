{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv into pandas dataframe\n",
    "df = pd.read_csv('goodreads_output.csv')\n",
    "df.loc[(df['year'].isin([2018]))]['category'].unique()\n",
    "df['category'] = df['category'].map({\n",
    "'Graphic Novels & Comics' : 0,\n",
    "'Young Adult Fiction' : 1,\n",
    "'Memoir & Autobiography' : 2,\n",
    "'Picture Books' : 3,\n",
    "'Romance' : 4,\n",
    "'Humor' : 5,\n",
    "'Poetry' : 6,\n",
    "'Horror' : 7,\n",
    "'Young Adult Fantasy' : 8,\n",
    "'Science Fiction' : 9,\n",
    "\"Middle Grade & Children's\" : 10,\n",
    "'History & Biography' : 11,\n",
    "'Nonfiction' : 12,\n",
    "'Fantasy': 13,\n",
    "'Mystery & Thriller' : 14,\n",
    "'Historical Fiction' : 15,\n",
    "'Debut Goodreads Author' : 16,\n",
    "'Fiction' : 17,\n",
    "'Paranormal Fantasy' : 18,\n",
    "'Food & Cookbooks' : 19,\n",
    "'Business Books' : 20,\n",
    "'Science & Technology' : 21,\n",
    "'Goodreads Author' : 22,\n",
    "'Debut Novel' : 23,\n",
    "'Best of the Best' : 24,\n",
    "'Travel & Outdoors' : 25,\n",
    "'Food & Cooking' : 19,\n",
    "'Favorite Book of 2011' : 24,\n",
    "'Debut Author' : 26\n",
    "})\n",
    "#df = df.loc[(df['category'].isin([21]))]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df[df.duplicated(['name', 'year', 'category'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num 1 stars', 'num 3 stars', 'num 4 stars', 'num 5 stars', 'average rating']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_norm = MinMaxScaler().fit_transform(X)\n",
    "chi_selector = SelectKBest(chi2, k=5)\n",
    "chi_selector.fit(X_norm, y)\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "print(chi_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 26,  9, 10, 11, 12, 13, 14, 15,\n",
       "       24, 21, 17, 19])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['num 1 stars', 'num 3 stars', 'num 4 stars', 'num 5 stars', 'average rating']\n",
    "data_test = df.loc[(df['year'].isin([2018]))]\n",
    "X_test = data_test[features]\n",
    "y_test = data_test['winner']\n",
    "data_test['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "fitting\n",
      "2012\n",
      "fitting\n",
      "2013\n",
      "fitting\n",
      "2014\n",
      "fitting\n",
      "2015\n",
      "fitting\n",
      "2016\n",
      "fitting\n",
      "2017\n",
      "fitting\n"
     ]
    }
   ],
   "source": [
    "# Use 2011 - 2017 as train data and 2018 as test data\n",
    "logreg = LogisticRegression(solver='liblinear', class_weight = 'balanced')\n",
    "for year in [2011, 2012, 2013, 2014, 2015, 2016, 2017]:\n",
    "    print(year)\n",
    "    data_temp = df.loc[~(df['year'].isin([2018,2019]))]\n",
    "    data_train = data_temp.loc[(data_temp['year'].isin([year]))]\n",
    "    X_train = data_train[features]\n",
    "    y_train = data_train['winner']\n",
    "    if(len(X_train) != 0) : \n",
    "        print('fitting')\n",
    "        logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    264\n",
       "1    160\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "predictions = pd.DataFrame(y_pred)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.63      0.76       403\n",
      "          1       0.06      0.48      0.11        21\n",
      "\n",
      "avg / total       0.91      0.62      0.73       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6202830188679245\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "#print('F1 score:', metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97       403\n",
      "          1       0.20      0.05      0.08        21\n",
      "\n",
      "avg / total       0.92      0.94      0.93       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=10, class_weight = 'balanced')\n",
    "for year in [2011, 2012, 2013, 2014, 2015, 2016, 2017]:\n",
    "    data_temp = df.loc[~(df['year'].isin([2018,2019]))]\n",
    "    data_train = data_temp.loc[(data_temp['year'].isin([year]))]\n",
    "    X_train = data_train[features]\n",
    "    y_train = data_train['winner']\n",
    "    if(len(X_train) != 0) : \n",
    "        rfc.fit(X_train, y_train)\n",
    "    \n",
    "rfc_pred = rfc.predict(X_test)\n",
    "metrics.accuracy_score(y_test, rfc_pred)\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "for year in [2011, 2012, 2013, 2014, 2015, 2016, 2017]:\n",
    "    data_temp = df.loc[~(df['year'].isin([2018,2019]))]\n",
    "    data_train = data_temp.loc[(data_temp['year'].isin([year]))]\n",
    "    X_train = data_train[features]\n",
    "    y_train = data_train['winner']\n",
    "    if(len(X_train) != 0) : \n",
    "        gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    410\n",
       "1     14\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_test)\n",
    "predictions = pd.DataFrame(y_pred)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96       403\n",
      "          1       0.07      0.05      0.06        21\n",
      "\n",
      "avg / total       0.91      0.92      0.91       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
